{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# magic! (don't worry about this)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us import some useful things\n",
    "from lib import *\n",
    "from classifiers import *\n",
    "#from graphs import *\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans as km_official"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's start with some simulated data in 2 dimensions so that we can visualize how the algorithm works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimensions of data:150 x 2\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1234)\n",
    "x1=np.random.uniform(1,5,[50,1])\n",
    "y1=np.random.uniform(5,10,[50,1])\n",
    "\n",
    "x2=np.random.uniform(15,20,[50,1])\n",
    "y2=np.random.uniform(10,15,[50,1])\n",
    "\n",
    "x3=np.random.uniform(8,14,[50,1])\n",
    "y3=np.random.uniform(4,15,[50,1])\n",
    "\n",
    "\n",
    "x=np.concatenate((x1,x2,x3),axis=0)\n",
    "y=np.concatenate((y1,y2,y3),axis=0)\n",
    "\n",
    "data=np.concatenate((x,y),axis=1)\n",
    "\n",
    "plt.plot(x,y,'bo')\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()\n",
    "\n",
    "print(\"dimensions of data:\"+str(data.shape[0])+\" x \" + str(data.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose some value of k. This will be the number of classes that you will use to group the data. \n",
    "\n",
    "K = 3 #replace 'None' with a value for K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now, we define all the helper functions we use in the K-means algorithm. If you feel like a taking on a bigger challenge, you can also write the algorithm yourself from scratch without using our helper function. To do this, write your code in the \"kmeans\" function in the file \"classifiers_skeleton.py\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Initialize k centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure each centroid falls within the range of the observed data in the x & y dimension \n",
    "# hint: the following function may be useful to you. But, you can also use np.random.randint. \n",
    "def random_val_in_range(low,high): \n",
    "    return low+(float(high)-low)*np.random.random()\n",
    "\n",
    "#inputs: data is your data matrix with samples in the rows and features in the columns. \n",
    "#output: an array of centroids. For example, if K=3, and we have 2-dimensional data (2 features), \n",
    "#we would return a np.array with dimensions 3x2\n",
    "\n",
    "#TODO: write a function to randomly initialize K centroids in the data \n",
    "def initialize_centroids(data,K):\n",
    "    samples,features = data.shape \n",
    "    centroids = np.zeros((K,features))#create an array to store your centroids. You will update these values. \n",
    "    np.random.seed(1234)\n",
    "    # your code here! \n",
    "    \n",
    "    return centroids "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: import the euclidean distance function that you wrote when we did the K-Nearest Neighbors algorithm\n",
    "# from classifiers_skeleton.py. (hint: look at the import statements at the top of this file)\n",
    "# You use \"import\" to pull in code from other Python files to avoid having to copy it over and over into multiple\n",
    "# files. \n",
    "\n",
    "from classifiers_skeleton import euclidean_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Assign each data point to nearest cluster by calculating its distance to each centroid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: write a function to find the nearest centroid to each point in a dataset \n",
    "# data in our example will be a 150x2 np.array and centroids will be a 3x2 np.array \n",
    "# hint: use your euclidean_distance function to loop over each point and loop over each centroid to calculate the \n",
    "# euclidean distance-- so 2 nested \"for\" loops. \n",
    "# although our specific example is 2 dimensional, your function should work with higher dimension data! \n",
    "\n",
    "#the output will be a list of labels 1 through K for each datapoint. \n",
    "def get_labels(centroids,data): \n",
    "    labels=[]  \n",
    "    num_centroids,num_features_centroids=centroids.shape \n",
    "    num_datapoints,num_features_data=data.shape \n",
    "    #sanity check -- your centroids and your data points should have the same number of features! \n",
    "    print(\"num_features_centroids: \" + str(num_features_centroids) + \" should equal num_features_data: \"+str(num_features_data))\n",
    "    \n",
    "    #your code here! \n",
    "    \n",
    "    return labels \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Find new centroids by calculating the average of the assigned points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: write a function that will update the K-means centroids based on the labels that were calculated above. \n",
    "\n",
    "#inputs: a np.array of size datapoints x features ( so 150 datapoints x 2 features in our example)\n",
    "#labels: a list of K labels that were assigned to the datapoints. \n",
    "#K : number of clusters to generate\n",
    "\n",
    "#output: a np.array of updated centroids. This array will be of size K x features (i.e. 3 centroids with 2 features\n",
    "#will mean you return a 3x2 array)\n",
    "def get_centroids(data,labels,K):\n",
    "    num_datapoints,num_features=data.shape \n",
    "    centroids=np.zeros((K,num_features)) #update the values in this array as you calculate your centroids. \n",
    "    return centroids \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Check to see if the algorithm should stop. If not, repeat Step 2 and 3 until none of the cluster assignments change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Check to see if the algorithm should stop \n",
    "#There are 2 conditions for the algorithm to stop: \n",
    "# 1. The cluster labels for the datapoints have not changed since the previous iteration \n",
    "# 2. The algorithm has exceeded the maximum number of iterations \n",
    " \n",
    "#inputs: \n",
    "# cur_iter -- the current iteration of the algorithm \n",
    "# max_iter -- the maximum allowed iterations of the algorithm \n",
    "# labels_old -- the labels that were assigned to the datapoints in the previous iteration \n",
    "# labels_new -- the labels that have been assigned to the datapoints in the most recent iteration \n",
    "\n",
    "#output: \n",
    "#The function returns \"True\" if we are finished, \"False\" if we are not finished\n",
    "def are_we_done(cur_iter,max_iter,labels_old,labels_new):\n",
    "    if labels_old==None: #this is an edge case -- the first time we iterate through the algorithm,labels_old will be None\n",
    "        return False \n",
    "    finished=False #if either of the conditions below are satisfied, change finished to True. \n",
    "    #check condition 1: \n",
    "    #your code here! \n",
    "    #check condition 2: \n",
    "    #your code here! \n",
    "    return finished "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main function for K-Means clustering algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Putting everything together. \n",
    "\n",
    "#Here, we use the functions you have implemented above to write the full K-means clustering algorithm. \n",
    "#The kmeans function accepts a np.array of data and a value for K, and returns a list of labels for your datapoints. \n",
    "def kmeans(data,K,max_iter): \n",
    "    #randomly initialize the centroids \n",
    "    centroids=initialize_centroids(data,K)\n",
    "    cur_iter=0 \n",
    "    labels_old=None \n",
    "    while True: \n",
    "        #assign cluster labels \n",
    "        labels=get_labels(centroids,data)\n",
    "        #check if we are done \n",
    "        finished=are_we_done(cur_iter,max_iter,labels_old,labels)\n",
    "        if finished: \n",
    "            break #exit the loop \n",
    "        else: \n",
    "            cur_iter+=1 #update the iteration number \n",
    "            labels_old=labels # update the labels_old variable\n",
    "            centroids=get_centroids(data,labels,K) #recalculate the centroids \n",
    "    #we have broken out of the while loop above, so we are finished. \n",
    "    #return the labels that have been calculated \n",
    "    return labels    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'max_iter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-8eeba09813fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#if you wrote your code from scratch, uncomment the following import statement:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#from classifiers_skeleton import *\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkmeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'max_iter' is not defined"
     ]
    }
   ],
   "source": [
    "#We test the k-means algorithm on our example dataset \n",
    "\n",
    "#if you wrote your code from scratch, uncomment the following import statement: \n",
    "#from classifiers_skeleton import * \n",
    "labels=kmeans(data,K,max_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-8de56b7d0753>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#plot your labeled data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'labels' is not defined"
     ]
    }
   ],
   "source": [
    "#plot your labeled data \n",
    "plt.scatter(data[:,0],data[:,1],s=60,c=labels)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, let's compare your algorithm to the 'official' implementation from Python \n",
    "#you may not get exactly the same answer (think about why that would be), but the color groups in the \n",
    "#plots should look fairly similar. \n",
    "\n",
    "kobj=km_official(n_clusters=K)\n",
    "labels_official=kobj.fit_predict(data)\n",
    "plt.scatter(data[:,0],data[:,1],s=60,c=labels_official)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102, 12533)\n",
      "102\n"
     ]
    }
   ],
   "source": [
    "#Run K-means clustering on our cancer dataset (this is a good way to test your implementation in high-dimensional space)\n",
    "# load the data\n",
    "microarray_file_name = '../data/prostate_normal_tumor_matrix.txt'\n",
    "labels_file_name = '../data/prostate_normal_tumor_labels.txt'\n",
    "data_store = DataSet(microarray_file_name, labels_file_name) # Data\n",
    "data=data_store.all_data\n",
    "true_labels=data_store.labels\n",
    "print(data.shape)\n",
    "print(len(true_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Cluster your dataset into 2 classes \n",
    "K=2 \n",
    "#your code here\n",
    "labels=None #replace None with the labels generated by your k-means algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the 'True' labels for the dataset \n",
    "from sklearn.manifold import TSNE \n",
    "#we project our 12533-dimensional data into 2 dimensions for visualization: \n",
    "model=TSNE(n_components=10,random_state=0)\n",
    "data2d=model.fit_transform(data)\n",
    "plt.scatter(data2d[:,0],data2d[:,1],s=60,c=true_labels)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the labels generated by your algorithm \n",
    "plt.scatter(data2d[:,0],data2d[:,1],s=60,c=labels)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
